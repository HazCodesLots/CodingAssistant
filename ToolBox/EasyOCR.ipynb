{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b0c7a4-1edc-4db7-ac9b-fe1bdc991318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "‚úÖ OCR extraction complete. Saved to: pdf_context.txt\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "pdf_path = r\"D:/Research Papers/Res2Net Forgery detection approach.pdf\"\n",
    "output_txt = \"pdf_context.txt\"\n",
    "\n",
    "pages = convert_from_path(pdf_path, dpi=300)\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, page in enumerate(pages):\n",
    "        print(f\"Processing page {i + 1}...\")\n",
    "        \n",
    "        image_path = f\"page_{i + 1}.jpg\"\n",
    "        page.save(image_path, 'JPEG')\n",
    "\n",
    "        results = reader.readtext(image_path)\n",
    "        \n",
    "        f.write(f\"\\n--- Page {i + 1} ---\\n\")\n",
    "        for _, text, _ in results:\n",
    "            f.write(text + \"\\n\")\n",
    "        \n",
    "        os.remove(image_path)\n",
    "\n",
    "print(f\"‚úÖ OCR extraction complete. Saved to: {output_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312a23e-2fc8-4949-82e2-dab0eec57345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import os\n",
    "\n",
    "openhermes_path = r\"C:\\GGUF\\TheBloke\\OpenHermes-2.5-Mistral-7B-GGUF\\openhermes-2.5-mistral-7b.Q4_K_M.gguf\"\n",
    "\n",
    "OpenHermes = Llama(\n",
    "    model_path=openhermes_path,\n",
    "    n_gpu_layers=20,\n",
    "    n_ctx=2048,\n",
    "    n_batch=256,\n",
    "    n_threads=6,\n",
    "    use_mlock=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d462378d-6329-43c1-90b3-dedb26d49cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pdf_context.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pdf_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69919849-5bb4-4464-ad7b-da3670ed65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context, question):\n",
    "    return f\"\"\"<|user|>\n",
    "Use the following paper content to answer the question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "<|assistant|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79163646-3762-490d-a2a8-3d73029176ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    prompt = build_prompt(pdf_text, question)\n",
    "    output = OpenHermes(prompt, max_tokens=512, stop=[\"<|user|>\"])\n",
    "    return output['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b0992a-33f4-4c04-8524-5cf7b37dc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "with open(\"pdf_context.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pdf_text = f.read()\n",
    "\n",
    "chunk_size = 500\n",
    "chunks = [pdf_text[i:i+chunk_size] for i in range(0, len(pdf_text), chunk_size)]\n",
    "\n",
    "embeddings = embedder.encode(chunks)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18ec646-f1af-4faf-b4c4-94023d3af48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(question, top_k=3):\n",
    "    q_embedding = embedder.encode([question])\n",
    "    _, I = index.search(q_embedding, top_k)\n",
    "    return \"\\n\\n\".join(chunks[i] for i in I[0])\n",
    "\n",
    "def ask(question):\n",
    "    context = retrieve_relevant_chunks(question)\n",
    "    prompt = f\"\"\"<|user|>\n",
    "Use the following context to answer the question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "<|assistant|>\"\"\"\n",
    "    response = OpenHermes(prompt, max_tokens=1024, stop=[\"<|user|>\"])\n",
    "    return response['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e15519-473f-4656-ac23-e2560d5ecb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Ask a question (or type 'exit'):  What is ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   21844.82 ms\n",
      "llama_perf_context_print: prompt eval time =   21844.15 ms /   542 tokens (   40.30 ms per token,    24.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =   19419.82 ms /   133 runs   (  146.01 ms per token,     6.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   41330.45 ms /   675 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Answer:\n",
      "ResNet is a type of neural network architecture that was introduced in the paper \"Deep Residual Learning for Image Recognition\" by He et al. It is designed to address the problem of degradation in network performance as the number of layers increases. ResNet achieves this by introducing a shortcut or \"skip\" connection between the input and output of the residual block. This allows the network to learn residual functions with respect to the input, essentially making it easier for the network to learn the desired transformation. ResNets have been widely used in various image recognition tasks and are known for their ability to handle depth and improve training efficiency.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Ask a question (or type 'exit'):  What is Residual block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 18 prefix-match hit, remaining 512 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   21844.82 ms\n",
      "llama_perf_context_print: prompt eval time =   16452.39 ms /   512 tokens (   32.13 ms per token,    31.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11102.99 ms /    75 runs   (  148.04 ms per token,     6.75 tokens per second)\n",
      "llama_perf_context_print:       total time =   27580.67 ms /   587 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Answer:\n",
      "A residual block is a neural network component that aims to address the degradation problem in deep neural networks by creating a shortcut or a \"residual path\" that allows the input to skip some layers and directly contribute to the output. The residual block was introduced in the ResNet architecture and has been widely used in various deep learning models since then.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Ask a question (or type 'exit'):  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    q = input(\"\\n‚ùì Ask a question (or type 'exit'): \")\n",
    "    if q.lower() in ['exit', 'quit']:\n",
    "        break\n",
    "    answer = ask(q)\n",
    "    print(f\"\\nüí¨ Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d08ff-32ad-457b-9710-2bd415299933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310-cuda]",
   "language": "python",
   "name": "conda-env-py310-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
